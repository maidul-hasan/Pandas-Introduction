{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:06.309478Z",
     "start_time": "2020-11-09T09:57:02.343512Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T16:01:43.986389Z",
     "start_time": "2020-11-04T16:01:42.947744Z"
    }
   },
   "source": [
    "#### Loading the Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.388161Z",
     "start_time": "2020-11-09T09:57:08.270275Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_dict = {\n",
    "    \"first\": [\"john\", \"jane\", \"dan\"],\n",
    "    \"last\": [\"doe\", \"doe\", \"james\"],\n",
    "    \"email\": [\"jd23@gmail.com\", \"jd21@yahoo.com\", \"dan543@outlook.com\"],\n",
    "}\n",
    "\n",
    "df_example = pd.DataFrame(sample_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = pd.DataFrame(sample_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.257801Z",
     "start_time": "2020-11-09T09:57:06.311126Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"PandasSampleData/survey_results_public.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.601773Z",
     "start_time": "2020-11-09T09:57:08.389897Z"
    },
    "hidden": true
   },
   "source": [
    "- Accessing a Single Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.601773Z",
     "start_time": "2020-11-09T09:57:08.389897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_dict[\"first\"];  # df_dict.first is the same as df_dict[\"first\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.601773Z",
     "start_time": "2020-11-09T09:57:08.389897Z"
    },
    "hidden": true
   },
   "source": [
    "- Accessing Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.601773Z",
     "start_time": "2020-11-09T09:57:08.389897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_dict[[\"first\", \"last\"]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.651970Z",
     "start_time": "2020-11-09T09:57:08.603853Z"
    },
    "hidden": true
   },
   "source": [
    "- Accessing Data by Locations of Rows and Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : Row Data can only be accessed using either loc or, iloc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : for 'iloc' the slicing is similar to list slicing and the end index is exclusive. But, for 'loc' it's inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.651970Z",
     "start_time": "2020-11-09T09:57:08.603853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0:2, 2:4];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:08.651970Z",
     "start_time": "2020-11-09T09:57:08.603853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.loc[0:1, \"Hobbyist\":\"Age\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by priority sequence of columns\n",
    "df_dict.sort_values(by=[\"last\", \"first\"], ascending=[True, False], inplace=True);\n",
    "# setting na_position=\"first\" will show the nan values first and then starts to sort values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To revert the inplace changes simply sort the DF by index\n",
    "df_dict.sort_index();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use .sort_values with Series Objects too\n",
    "df_dict[\"last\"].sort_values();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:09.731350Z",
     "start_time": "2020-11-09T09:57:09.633014Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we can pass the conditions in df_name to filter the data and create a DF as per the conditions.\n",
    "filt = (df_dict[\"last\"] == \"doe\")\n",
    "filt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:10.787486Z",
     "start_time": "2020-11-09T09:57:10.630372Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can also use loc to filter out data by passing in a boolean series data...\n",
    "# ...This way we can also define which columns do we want in our new DF.\n",
    "df_dict.loc[filt, \"email\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note : As We Can't use python default \"and\", \"or\" for filtering so, we will use \"&\" and \"|\".\n",
    "And To have the negation of a filtering condition we use \"~\" before the condition as we pass it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:10.905587Z",
     "start_time": "2020-11-09T09:57:10.789627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filt = (df_dict[\"last\"] == \"doe\") | (df_dict[\"first\"] == \"john\")\n",
    "df_dict.loc[~filt, \"email\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : We can also use .where() and .query() method to filter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : we can also use some of the available str methods i.e., .str.contains(), .str.startswith(), .str.endswith() etc. to filter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Rows & Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T17:09:37.958894Z",
     "start_time": "2020-11-08T17:09:37.890900Z"
    }
   },
   "source": [
    "### Modifying Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Renaming Existing Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:10.994720Z",
     "start_time": "2020-11-09T09:57:10.910517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using \".rename\" method to rename a particular Column\n",
    "df_dict.rename(columns={\"first\": \"first name\", \"last\": \"last name\"}); # by default inplace is set to False\n",
    "# bad practice as it complicates the use of dot natation to access the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:10.994720Z",
     "start_time": "2020-11-09T09:57:10.910517Z"
    }
   },
   "outputs": [],
   "source": [
    "# to change names of all of the columns\n",
    "df_dict.columns = [\"email\", \"first name\", \"last name\"] \n",
    "# Changes the column names inplace & sequentially according to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modifying the existing column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:10.994720Z",
     "start_time": "2020-11-09T09:57:10.910517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying list comprehension to apply some of string methods to the column names\n",
    "df_dict.columns = [x.capitalize() for x in df_dict.columns]\n",
    "# Using \".str\" Class to apply some of string methods to the column names\n",
    "df_dict.columns = df_dict.columns.str.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : the difference between these two method is that the first will always add the column to the last of the DF and using the second method we can add the column to any position along the axis 1 by defining the index position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"Country\"] = \"USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.insert(3, column=\"Full_name\", value=df_dict[\"First_name\"] + \" \" + df_dict[\"Last_name\"])\n",
    "df_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deleting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.drop(columns=[\"First_name\", \"Last_name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding back the deleted columns\n",
    "df_dict[[\"First_name\", \"Last_name\"]] = df_dict[\"Full_name\"].str.split(\" \", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying Rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updating Row Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:11.098534Z",
     "start_time": "2020-11-09T09:57:10.999981Z"
    }
   },
   "outputs": [],
   "source": [
    "# to update a single row of data\n",
    "df_dict.loc[0] = [\"js23@gmail.com\", \"john smith\", \"USA\", \"john\", \"smith\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:11.098534Z",
     "start_time": "2020-11-09T09:57:10.999981Z"
    }
   },
   "outputs": [],
   "source": [
    "# to update a particular |row,column| data\n",
    "df_dict.loc[1, \"Last_name\"] = \"austen\"  # we can also pass in filter condition to 'loc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:11.098534Z",
     "start_time": "2020-11-09T09:57:10.999981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying string methods to the data of a particular Row\n",
    "for x in [\"First_name\", \"Last_name\", \"Full_name\"]:\n",
    "    df_dict[x] = df_dict[x].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T09:57:11.098534Z",
     "start_time": "2020-11-09T09:57:10.999981Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding New Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Single Row\n",
    "df_dict = df_dict.append({\"Email\": \"maidulhasan956@gmail.com\",\n",
    "                          \"Full_name\": \"Maidul Hasan\",\n",
    "                          \"Country\": \"BD\",\n",
    "                          \"First_name\": \"Maidul\",\n",
    "                          \"Last_name\": \"Hasan\"}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Multiple Rows\n",
    "# Pass in a list of the row dicts in the .append method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deleting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = (df_dict[\"Country\"] == \"BD\")\n",
    "df_dict.drop(index= df_dict.loc[filt].index);  # inplace=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Row Manipulation Using apply, applymap, map & replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(sample_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T10:00:59.813875Z",
     "start_time": "2020-11-09T10:00:59.806927Z"
    }
   },
   "source": [
    "- apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : 'apply' can be used with both Data Frames and Series Objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T10:00:59.813875Z",
     "start_time": "2020-11-09T10:00:59.806927Z"
    }
   },
   "outputs": [],
   "source": [
    "# In a Series object 'apply' applies a function to every value in the series.\n",
    "new_df[\"first\"] = new_df[\"first\"].apply(lambda x: x.lower())\n",
    "# In a Data Frame it runs a function on each Series of data along the defined axis of that data frame\n",
    "new_df.apply(pd.Series.min);  # the default value of axis is axis=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T10:08:21.433041Z",
     "start_time": "2020-11-09T10:08:21.411765Z"
    }
   },
   "source": [
    "- applymap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : 'applymap' can only be used on DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T10:08:21.433041Z",
     "start_time": "2020-11-09T10:08:21.411765Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'applymap' runs a function on every single element of the data frame\n",
    "new_df.applymap(lambda x: x.lower());  # applymap(str.lower) has the samne effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : 'map' only works on a Series object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T10:18:06.180099Z",
     "start_time": "2020-11-09T10:18:06.172146Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'map' changes the element values according to the instruction dictionary and it replaces the remaining values to 'NaN'\n",
    "new_df[\"first\"].map({\"john\": \"snow\", \"jane\": \"chris\"});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : 'replace' can be used on a Series object as well as a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-09T10:20:05.748691Z",
     "start_time": "2020-11-09T10:20:05.737001Z"
    }
   },
   "outputs": [],
   "source": [
    "# in Series objects 'replace' changes element values according to the instruction dictionary and\n",
    "# leaves out the remaining values unchanged.\n",
    "new_df[\"first\"].replace({\"john\": \"snow\", \"jane\": \"chris\"});\n",
    "# in a DF 'replace' replces a certain value with another wherever this certain value appears in the DF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying the Dataframe as a Whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = pd.read_csv(\"PandasSampleData/worldstats.csv\", index_col=[\"country\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"PandasSampleData/salesmen.csv\", parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_sales = pd.read_csv(\"PandasSampleData/foods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_sales = pd.read_csv(\"PandasSampleData/quarters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The stack ( ) method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What the stack() method does is, it basically pulls/turns all of the columns in the DF to the last level of a multi-indexed DF's row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country     year            \n",
       "Arab World  2015  Population    3.920223e+08\n",
       "                  GDP           2.530102e+12\n",
       "            2014  Population    3.842226e+08\n",
       "                  GDP           2.873600e+12\n",
       "            2013  Population    3.765043e+08\n",
       "                                    ...     \n",
       "Zimbabwe    1962  GDP           1.117602e+09\n",
       "            1961  Population    3.876638e+06\n",
       "                  GDP           1.096647e+09\n",
       "            1960  Population    3.752390e+06\n",
       "                  GDP           1.052990e+09\n",
       "Length: 22422, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The unstack ( ) method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> unstack() does the opposite of stack(). It unstacks the last/most inner level of a multi-indexed DF to a column index level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The pivot ( ) method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What pivot() method basically does is, it takes in a column as input of columns parameter and converts the unique values in that column to new columns and populates these new columns using the data from the columns that was specified as input of the parameter values.\n",
    "\n",
    "> Note that, the columns specified in the values parameter becomes the 1st level of the column multi-index and the newly created columns by the pivot() method becomes the 2nd level of the column multi-index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salesman</th>\n",
       "      <th>Bob</th>\n",
       "      <th>Dave</th>\n",
       "      <th>Jeb</th>\n",
       "      <th>Oscar</th>\n",
       "      <th>Ronald</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>7172</td>\n",
       "      <td>1864</td>\n",
       "      <td>4430</td>\n",
       "      <td>5250</td>\n",
       "      <td>2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>6362</td>\n",
       "      <td>8278</td>\n",
       "      <td>8026</td>\n",
       "      <td>8661</td>\n",
       "      <td>4951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>5982</td>\n",
       "      <td>4226</td>\n",
       "      <td>5188</td>\n",
       "      <td>7075</td>\n",
       "      <td>2703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Revenue                         \n",
       "Salesman       Bob  Dave   Jeb Oscar Ronald\n",
       "Date                                       \n",
       "2016-01-01    7172  1864  4430  5250   2639\n",
       "2016-01-02    6362  8278  8026  8661   4951\n",
       "2016-01-03    5982  4226  5188  7075   2703"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sales.info()\n",
    "# sales[\"Salesman\"].nunique()\n",
    "sales[\"Salesman\"] = sales[\"Salesman\"].astype(\"category\")\n",
    "pivot_sales = sales.pivot(index=\"Date\", columns=\"Salesman\", values=[\"Revenue\"])\n",
    "pivot_sales.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The pivot_table ( ) method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The pivot_table() is actually the same as the pivot() method except that, it takes an extra parameter named aggfunc and as a input to this param we can enter an aggregate functions name and this function will be applied to the column specified as the input of the parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_sales.head(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_sales.pivot_table(index=[\"Gender\", \"City\"], columns=\"Item\", values=\"Spend\", aggfunc=\"mean\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The melt ( ) method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It's the opposite of the pivot() method. It unpivots a DataFrame from wide format to long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_sales.melt(id_vars=[\"Salesman\"], value_vars=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "                   var_name=\"Quarter\", value_name=\"Revenue\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data - Handling Missing Values & Casting Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = df_dict.append(\n",
    "    [{\"First_name\": \"Harry\", \"Last_name\": \"Kane\", \"Email\": \"N/A\", \"Full_name\": \"Harry Kane\"}],\n",
    "    ignore_index=True,\n",
    ")\n",
    "df_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : though .dropna() can remove rows/columns that has NaN/None value by the defined conditions but, it can't remove rows/columns that has customized missing values i.e. strings like 'NA'/'Missing' etc. To handle such data we can simply replace those certain strings with '.replace' method. Alternatively if the data was read from a .csv file then we would simply pass in a list of those customized missing values that we want to treat as NaN values while loading the .csv file as a DF. i.e.\n",
    "\n",
    "> df = pd.read_csv(\"file path\", na_values=['NA', 'N/A', 'Missing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop rows/columns with NaN/None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.dropna(axis=\"index\", how=\"any\", subset=[\"Country\", \"Email\"]);  # inplace=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : Default is set to (axis=\"index\", how=\"any\"). To remove columns set axis=\"columns\".\n",
    "\n",
    "> how=\"any\" removes rows/columns when 'atleast one' of the <col_name> in the subset parameter has NaN/None value & how=\"all\" removes rows/columns when 'all' of the <col_names> in the subset parameter has NaN/None value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop rows/columns with custom missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.replace(\"N/A\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.dropna(subset=[\"Email\"], inplace=True)\n",
    "df_dict;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note : To replace NaN values of the entire DF we can either use .replace() or .fillna() method. To see a mask (True/False DF) of which elements in a certain DataFrame will be treated as a NaN values use .isna() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting Data-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].astype(np.str);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
